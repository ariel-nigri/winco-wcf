#!/bin/env php
<?php

require dirname(__DIR__).'/common/wcf.php';

$verbose = true;

$inst_seq = @$argv[1];

if (!is_numeric($inst_seq) || !is_dir("/home/instances/{$inst_seq}")) {
	fputs(STDERR, "Invalid instance ID.\n\nusage: {$argv[0]} inst_id\n\n");
	exit(1);
}

$client = getAwsS3Client();

$logs_dir = "/home/instances/{$inst_seq}/var/winco/logs";
$years = glob("{$logs_dir}/20??");

foreach ($years as $year) {
	echo "Vendo {$year}\n";
	$y = basename($year);

	// sync the log files into the bucket
	sync_log_files($client, $aws_instance_bucket, "{$inst_seq}/logs/{$y}", "{$logs_dir}/{$y}");

	// erase old log files.
	clean_log_files($client, $aws_instance_bucket, "{$inst_seq}/logs/{$y}", "{$logs_dir}/{$y}");
}


function sync_log_files($client, $bucket, $rdir, $sdir)
{
	global $verbose;

	$rlist = [];
	try {
		$iterator = $client->getIterator('ListObjects', array(
			'Bucket' => $bucket,
			'Prefix' => "{$rdir}/"
		));

		foreach ($iterator as $file)
			$rlist[$file['Key']] = $file['Size'];
	}
	catch (Exception $e) {
		if ($verbose)
			echo 'Caught exception [', get_class($e), ']: ', $e->getMessage(), "\n";
		exit(1);
	}

	$files = glob("{$sdir}/*.LOG.gz");
	foreach ($files as $lfile) {
		$rfile = "{$rdir}/".basename($lfile);
		$lsize = filesize($lfile);
		if ($lsize == @$rlist[$rfile]) {
			echo "File {$rfile} is already uploaded and with the same size\n";
			continue;
		}

		echo "Will upload {$rfile}\n";
		$nretries = 3;
		$ok = false;
		do {
			try {
				$client->putObject(array(
						'Bucket'     => $bucket,
						'Key'        => $rfile,
						'SourceFile' => $lfile,
						'Metadata'	 => array(
							'originalmodificationdate' => $lsize
						)
					)
				);
				$ok = true;
				break;
			}
			catch (Exception $e) {
				echo "Exception on upload of {$rfile}: " . $e->getMessage() . "..retrying..\n";
			}
		 } while (--$nretries > 0);
		 if (!$ok) {
			fputs(STDERR, "Too many retries: will stop.\n");
			exit(1);
		 }
	}
}

function clean_log_files($client, $bucket, $rdir, $ldir)
{
	global $verbose;

	$lfiles = [];
	$todel = time() - (7 * 86400);

	$files = glob("{$ldir}/*.LOG.gz");
	foreach ($files as $lfile) {
		$ltime = filemtime($lfile);
		if ($ltime > $todel) {
			echo "File is too recent\n";
			continue;
		}

		$lfiles["{$rdir}/".basename($lfile)] = filesize($lfile);
	}

	if (count($lfiles) == 0) {
		echo "Nothing to delete\n";
		return;
	}

	// before deleting we need to make sure the file is already uploaded.
	$rlist = [];
	try {
		$iterator = $client->getIterator('ListObjects', array(
			'Bucket' => $bucket,
			'Prefix' => "{$rdir}/"
		));

		foreach ($iterator as $file)
			$rlist[$file['Key']] = $file['Size'];
	}
	catch (Exception $e) {
		if ($verbose)
			echo 'Caught exception [', get_class($e), ']: ', $e->getMessage(), "\n";
		exit(1);
	}
	foreach ($lfiles as $rfile => $lsize) {
		if ($lsize == @$rlist[$rfile]) {
			// file is uploaded and with correct size.
			$lfile = $ldir."/".basename($rfile);
			unlink($ldir."/".basename($rfile));
			echo "Erasing {$lfile}\n";
		}
	}
}
